{"code": "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", "rule": "motif_enrichment_cistarget", "input": ["/group/testa/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/region_sets", "/group/testa/michal.kubacki/herring/scenic_input/motifs-v9-nr.hgnc-m0.001-o0.0.tbl", "/scratch/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/cistarget_motif_dataset.regions_vs_motifs.rankings.feather"], "log": [], "params": ["'/group/testa/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/tmp'", "'Direct_annot Orthology_annot'", "'homo_sapiens'", "'v9'", "0.0", "0.001", "0.005", "0.05", "0.4", "3.0"], "shellcmd": "\n            scenicplus grn_inference motif_enrichment_cistarget                 --region_set_folder /group/testa/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/region_sets                 --cistarget_db_fname /scratch/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/cistarget_motif_dataset.regions_vs_motifs.rankings.feather                 --output_fname_cistarget_result /group/testa/michal.kubacki/herring/scenic_all_excitatory_trimmed/ctx_results.hdf5                 --temp_dir /group/testa/michal.kubacki/herring/output_hg19_all_excitatory_trimmed/tmp                 --species homo_sapiens                 --fr_overlap_w_ctx_db 0.4                 --auc_threshold 0.005                 --nes_threshold 3.0                 --rank_threshold 0.05                 --path_to_motif_annotations /group/testa/michal.kubacki/herring/scenic_input/motifs-v9-nr.hgnc-m0.001-o0.0.tbl                 --annotation_version v9                 --motif_similarity_fdr 0.001                 --orthologous_identity_threshold 0.0                 --annotations_to_use Direct_annot Orthology_annot                 --write_html                 --output_fname_cistarget_html /group/testa/michal.kubacki/herring/scenic_all_excitatory_trimmed/ctx_results.html                 --n_cpu 32\n        ", "incomplete": false, "starttime": 1719553029.298476, "endtime": 1719553681.64789, "job_hash": 1466012070951, "conda_env": null, "container_img_url": null, "input_checksums": {}}