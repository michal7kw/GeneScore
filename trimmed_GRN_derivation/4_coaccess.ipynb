{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9593ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycisTopic import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.insert(0, os.getenv('PROJECT_FUNCTIONS_PATH'))\n",
    "\n",
    "from grn_helpers import set_output_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9834ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpus = 8\n",
    "neurons_set = \"L2-3_CUX2\"\n",
    "# neurons_set = \"all_ex\"\n",
    "# neurons_set = \"all_ex_all_ages\"\n",
    "root_dir = os.getenv('BASE_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2275e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_dir: /group/testa/michal.kubacki/herring_minimal\n",
      "out_dir: /group/testa/michal.kubacki/herring_minimal/L2-3_CUX2\n",
      "in_dir: /group/testa/michal.kubacki/herring_minimal/data\n",
      "tmp_dir: /group/testa/michal.kubacki/herring_minimal/tmp\n"
     ]
    }
   ],
   "source": [
    "out_dir, in_dir, root_dir, tmp_dir, data_folder = set_output_folders(root_dir, neurons_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22208c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cistopic_obj\n",
      "Get the fragment matrix and peak names from the cisTopic object\n",
      "fragment_matrix_ori.shape: (170045, 1796)\n",
      "peak_names: ['chr1_762659_763159', 'chr1_875527_876027', 'chr1_878463_878963', 'chr1_894443_894943', 'chr1_895685_896185', 'chr1_911692_912192', 'chr1_919519_920019', 'chr1_933824_934324', 'chr1_934495_934995', 'chr1_935333_935833']\n"
     ]
    }
   ],
   "source": [
    "print(\"Load cistopic_obj\")\n",
    "file_path = os.path.join(out_dir, \"cistopic_obj.pkl\")\n",
    "with open(file_path, \"rb\") as file:\n",
    "    cistopic_obj = pickle.load(file)\n",
    "\n",
    "print(\"Get the fragment matrix and peak names from the cisTopic object\")\n",
    "fragment_matrix_ori = cistopic_obj.fragment_matrix\n",
    "peak_names = cistopic_obj.region_names\n",
    "peak_names = [f\"{name.split(':')[0]}_{name.split(':')[1].replace('-', '_')}\" for name in peak_names]\n",
    "print(f\"fragment_matrix_ori.shape: {fragment_matrix_ori.shape}\")\n",
    "print(F\"peak_names: {peak_names[:10]}\")\n",
    "\n",
    "    \n",
    "cells_dict = {\n",
    "    \"all_ex\"            :   ['L5-6_TLE4', 'L2-3_CUX2', 'L4_RORB', 'L5-6_THEMIS', 'PN_dev'],\n",
    "    \"all_ex_all_ages\"   :   ['L5-6_TLE4', 'L2-3_CUX2', 'L4_RORB', 'L5-6_THEMIS', 'PN_dev'],\n",
    "    \"L2-3_CUX2\"         :   ['L2-3_CUX2']\n",
    "}\n",
    "\n",
    "cell_types = cells_dict[neurons_set]\n",
    "\n",
    "cell_type_dir = os.path.join(out_dir, \"cell_type_consensus_regions\")\n",
    "cell_type_fragments_dir = os.path.join(out_dir, \"cell_type_fragments_data\")\n",
    "\n",
    "cell_types = list(reversed(cell_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686ec653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L2-3_CUX2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in cell_types:\n",
    "    print(f\"Processing cell type: {cell_type}\")\n",
    "\n",
    "    print(f\"Loading consensus regions for {cell_type}\")\n",
    "    cell_type_regions_file = os.path.join(cell_type_dir, f\"{cell_type}_consensus_regions.bed\")\n",
    "    cell_type_regions = pd.read_csv(cell_type_regions_file, sep='\\t', header=None)\n",
    "    cell_type_regions.columns = ['chrom', 'start', 'end', 'peak_id', 'score', 'strand', 'peak_name', 'cell_type']\n",
    "    cell_type_regions.head()\n",
    "\n",
    "    print(f\"Creating peak_id to peak_name mapping for {cell_type}\")\n",
    "    peak_id_to_name = {}\n",
    "    for peak_id, peak_name in zip(cell_type_regions['peak_id'], cell_type_regions['peak_name']):\n",
    "        if ',' in peak_id:\n",
    "            peak_ids = peak_id.split(',')\n",
    "            for p_id in peak_ids:\n",
    "                peak_id_to_name[p_id] = peak_name\n",
    "        else:\n",
    "            peak_id_to_name[peak_id] = peak_name\n",
    "    first_10_elements = dict(islice(peak_id_to_name.items(), 10))\n",
    "    print(first_10_elements)\n",
    "\n",
    "    print(f\"Loading cell_type_peak_indices for {cell_type}\")\n",
    "    cell_type_peak_indices_file = os.path.join(out_dir, f\"{cell_type}_peak_indices.pkl\")\n",
    "    if os.path.exists(cell_type_peak_indices_file):\n",
    "        print(\"Retriving from a file\")\n",
    "        with open(cell_type_peak_indices_file, \"rb\") as file:\n",
    "            cell_type_peak_indices = pickle.load(file)\n",
    "    else:\n",
    "        print(\"Generating\")\n",
    "        print(f\"cell_type_regions['peak_id']: {cell_type_regions['peak_id'][:10]}\")\n",
    "        cell_type_peak_indices = []\n",
    "        for peak_id in cell_type_regions['peak_id']:\n",
    "            if peak_id in peak_id_to_name and peak_id_to_name[peak_id] in peak_names:\n",
    "                cell_type_peak_indices.append(peak_names.index(peak_id_to_name[peak_id]))\n",
    "        with open(cell_type_peak_indices_file, \"wb\") as file:\n",
    "            pickle.dump(cell_type_peak_indices, file)\n",
    "\n",
    "    print(f\"Processing {len(cell_type_peak_indices)} peak indices for {cell_type}\")\n",
    "\n",
    "    max_value = max(cell_type_peak_indices)\n",
    "    min_value = min(cell_type_peak_indices)\n",
    "\n",
    "    print(\"Maximum value:\", max_value)\n",
    "    print(\"Minimum value:\", min_value)\n",
    "\n",
    "    valid_indices = np.array(cell_type_peak_indices)\n",
    "\n",
    "    if len(valid_indices) > 0:\n",
    "        chunk_size = 10000\n",
    "        num_chunks = len(valid_indices) // chunk_size + 1\n",
    "        coaccess_results = []\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min((i + 1) * chunk_size, len(valid_indices))\n",
    "            chunk_indices = valid_indices[start_idx:end_idx]\n",
    "\n",
    "            max_value = np.max(chunk_indices)\n",
    "            min_value = np.min(chunk_indices)\n",
    "\n",
    "            print(\"chunk_indices Maximum value:\", max_value)\n",
    "            print(\"chunk_indices Minimum value:\", min_value)\n",
    "\n",
    "            fragment_matrix_chunk = fragment_matrix_ori[chunk_indices, :]\n",
    "            fragment_matrix_chunk = (fragment_matrix_chunk > 0).astype(np.bool_)\n",
    "            corr_matrix_chunk = cosine_similarity(fragment_matrix_chunk)\n",
    "\n",
    "            upper_tri_indices = np.triu_indices(corr_matrix_chunk.shape[0], k=1)\n",
    "\n",
    "            peak1_indices_chunk = upper_tri_indices[0]\n",
    "            peak2_indices_chunk = upper_tri_indices[1]\n",
    "            correlations_chunk = corr_matrix_chunk[peak1_indices_chunk, peak2_indices_chunk]\n",
    "\n",
    "            mask_chunk = np.abs(correlations_chunk) > 0.2\n",
    "\n",
    "            peak1_indices_chunk = peak1_indices_chunk[mask_chunk]\n",
    "            peak2_indices_chunk = peak2_indices_chunk[mask_chunk]\n",
    "            correlations_chunk = correlations_chunk[mask_chunk]\n",
    "\n",
    "            coaccess_results_chunk = np.column_stack((chunk_indices[peak1_indices_chunk], chunk_indices[peak2_indices_chunk], correlations_chunk))\n",
    "            coaccess_results.append(coaccess_results_chunk)\n",
    "\n",
    "        coaccess_results = np.concatenate(coaccess_results, axis=0)\n",
    "\n",
    "        coaccess_df = pd.DataFrame(coaccess_results, columns=['Peak1_idx', 'Peak2_idx', 'coaccess'])\n",
    "\n",
    "        print(f\"Mapping peak indices to peak names for {cell_type}\")\n",
    "        coaccess_df['Peak1'] = coaccess_df['Peak1_idx'].astype(int).map(lambda x: peak_names[x].replace(':', '_').replace('-', '_'))\n",
    "        coaccess_df['Peak2'] = coaccess_df['Peak2_idx'].astype(int).map(lambda x: peak_names[x].replace(':', '_').replace('-', '_'))\n",
    "\n",
    "        coaccess_df = coaccess_df.drop(columns=['Peak1_idx', 'Peak2_idx'])\n",
    "\n",
    "        print(f\"Saving co-accessibility results for {cell_type}\")\n",
    "        coaccess_df.to_csv(os.path.join(out_dir, f\"{cell_type}_coaccess.csv\"), index=False)\n",
    "\n",
    "        print(f\"Co-accessibility results for cell type {cell_type} saved to {cell_type}_coaccess.csv\")\n",
    "    else:\n",
    "        print(f\"Skipping cell type {cell_type} due to out-of-bounds indices\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (scenicplus)",
   "language": "python",
   "name": "scenicplus"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
