{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "import cudf\n",
    "import rmm\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pyranges import PyRanges\n",
    "from pyfaidx import Fasta\n",
    "import importlib\n",
    "\n",
    "import celloracle as co\n",
    "from celloracle import motif_analysis as ma\n",
    "co.__version__\n",
    "\n",
    "import GRN_Helpers \n",
    "importlib.reload(GRN_Helpers)\n",
    "from GRN_Helpers import *\n",
    "\n",
    "\n",
    "import config \n",
    "importlib.reload(config)\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "plt.rcParams[\"savefig.dpi\"] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/age_Neonatal0_celltypes_PN/\n"
     ]
    }
   ],
   "source": [
    "folder, select_by_age_groups, select_by_cells_groups, selected_day, selected_ages, selected_celltypes = config.setup_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m08:37:23\u001b[0m \u001b[1m|\u001b[0m \u001b[34mWARNING\u001b[0m \u001b[1m|\u001b[0m UCSC appears to be offline.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal.kubacki/.conda/envs/rapids/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import genomepy\n",
    "genomepy.install_genome(name=\"hg19\", provider=\"UCSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg19 installation:  True\n"
     ]
    }
   ],
   "source": [
    "ref_genome = \"hg19\"\n",
    "\n",
    "genome_installation = ma.is_genome_installed(ref_genome=ref_genome,\n",
    "                                             genomes_dir=None)\n",
    "print(ref_genome, \"installation: \", genome_installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FastaNotFoundError",
     "evalue": "Cannot read FASTA from file /home/michal/.local/share/genomes/hg19/hg19.fa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/rapids/lib/python3.9/site-packages/pyfaidx/__init__.py:391\u001b[0m, in \u001b[0;36mFaidx.__init__\u001b[0;34m(self, filename, indexname, default_seq, key_function, as_raw, strict_bounds, read_ahead, mutable, split_char, duplicate_action, filt_function, one_based_attributes, read_long_names, sequence_always_upper, rebuild, build_index)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr+b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmutable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/michal/.local/share/genomes/hg19/hg19.fa'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFastaNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hg19_genome \u001b[38;5;241m=\u001b[39m \u001b[43mFasta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/michal/.local/share/genomes/hg19/hg19.fa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rapids/lib/python3.9/site-packages/pyfaidx/__init__.py:1090\u001b[0m, in \u001b[0;36mFasta.__init__\u001b[0;34m(self, filename, indexname, default_seq, key_function, as_raw, strict_bounds, read_ahead, mutable, split_char, filt_function, one_based_attributes, read_long_names, duplicate_action, sequence_always_upper, rebuild, build_index)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03mAn object that provides a pygr compatible interface.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03mfilename:  name of fasta file or fsspec.core.OpenFile instance\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03mindexname: name of index file or fsspec.core.OpenFile instance\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutable \u001b[38;5;241m=\u001b[39m mutable\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaidx \u001b[38;5;241m=\u001b[39m \u001b[43mFaidx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_seq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_ahead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_ahead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilt_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilt_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_based_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mone_based_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_long_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_long_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicate_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicate_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_always_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_always_upper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrebuild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaidx\u001b[38;5;241m.\u001b[39mfilename\n\u001b[1;32m   1110\u001b[0m _record_constructor \u001b[38;5;241m=\u001b[39m MutableFastaRecord \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutable \u001b[38;5;28;01melse\u001b[39;00m FastaRecord\n",
      "File \u001b[0;32m~/.conda/envs/rapids/lib/python3.9/site-packages/pyfaidx/__init__.py:393\u001b[0m, in \u001b[0;36mFaidx.__init__\u001b[0;34m(self, filename, indexname, default_seq, key_function, as_raw, strict_bounds, read_ahead, mutable, split_char, duplicate_action, filt_function, one_based_attributes, read_long_names, sequence_always_upper, rebuild, build_index)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mutable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FastaNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot read FASTA from file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFastaNotFoundError\u001b[0m: Cannot read FASTA from file /home/michal/.local/share/genomes/hg19/hg19.fa"
     ]
    }
   ],
   "source": [
    "hg19_genome = Fasta('/home/michal/.local/share/genomes/hg19/hg19.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `Processed_data_ATAC_processed-count-data.h5ad`\n",
    "\n",
    "Output:\n",
    "- peaks.csv\n",
    "- peaks_extended_format.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_adata = sc.read_h5ad(f'{folder}subseted_herring_atac_andata_.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_adata)\n",
    "print(atac_adata.var.shape)\n",
    "print(atac_adata.obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = atac_adata.var\n",
    "peaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_adata.var.start.head() - atac_adata.var.end.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Chromosome name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.SUPPORTED_REF_GENOME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks.insert(0, 'Chromosome', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks.rename(columns={'start': 'Start', 'end': 'End'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_pr = PyRanges(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hg19_genome.keys())\n",
    "print(len(hg19_genome['chr20']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chromosome(row):\n",
    "    for chrom in hg19_genome.keys():\n",
    "        chrom_length = len(hg19_genome[chrom])\n",
    "        if row['Start'] >= 0 and row['End'] <= chrom_length:\n",
    "            return chrom\n",
    "    return ''\n",
    "\n",
    "peaks['Chromosome'] = peaks.apply(get_chromosome, axis=1)\n",
    "\n",
    "peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_chromosomes = peaks['Chromosome'].eq('').sum()\n",
    "print(f\"Number of empty chromosomes: {empty_chromosomes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = peaks['Chromosome'] \n",
    "starts = peaks['Start'] \n",
    "ends = peaks['End'] \n",
    "names = peaks['name']\n",
    "\n",
    "peaks_extended_format = pd.DataFrame({'Chr': chromosomes, 'Start': starts, 'End': ends, 'Gene': names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_extended_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks['peak_id'] = peaks['Chromosome'] + '_' + peaks['Start'].astype(str) + '_' + peaks['End'].astype(str)\n",
    "\n",
    "peaks = peaks.rename(columns={'name': 'gene_short_name'})\n",
    "\n",
    "peaks = peaks[['peak_id', 'gene_short_name']]\n",
    "\n",
    "peaks = peaks.reset_index(drop=True)\n",
    "\n",
    "peaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = ma.check_peak_format(peaks, ref_genome, genomes_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save `peaks.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks.to_csv(f'{folder}peaks.csv', index=True)\n",
    "peaks_extended_format.to_csv(f'{folder}peaks_extended_format.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match TFs and Gene regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `AllCellTypesRegReg.bed`\n",
    "Output:\n",
    "- peak_df (284150, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df = pd.read_csv(\"./input_data/AllCellTypesRegReg.bed\", index_col=None,sep='\\t').loc[:,['name','gene']]\n",
    "peak_df.columns = ['peak_id','gene_short_name']\n",
    "print(peak_df.shape)\n",
    "peak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df[['Chr', 'Start', 'End']] = peak_df['peak_id'].str.split('_', expand=True)\n",
    "\n",
    "peak_df['Start'] = pd.to_numeric(peak_df['Start'])\n",
    "peak_df['End'] = pd.to_numeric(peak_df['End'])\n",
    "\n",
    "print(peak_df.head().Start - peak_df.head().End) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peak_df['gene_short_name'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load promoters data\n",
    "Output:\n",
    "- promoters_1 (22241, 4)\n",
    "- promoters_2 (29595, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input_data/promoters/hg19_all_genes_TSS_2_2.txt', sep='\\t')\n",
    "promoters_1 = data[['Chr', 'Start', 'End', 'Gene']]\n",
    "print(promoters_1.shape)\n",
    "promoters_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promoters_1.head().Start - promoters_1.head().End)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promoters_2 = pd.read_csv('./input_data/promoters/epdnew_hg38ToHg19_ANySn.bed', sep='\\t', header=None, usecols=[0, 1, 2, 3])\n",
    "# promoters_2.columns = ['Chr', 'Start', 'End', 'Gene']\n",
    "# print(promoters_2.shape)\n",
    "# promoters_2.head()\n",
    "\n",
    "# promoters_2['Gene'] = promoters_2['Gene'].str.replace(r'_\\d+$', '', regex=True)\n",
    "# promoters_2.head()\n",
    "\n",
    "# print(promoters_2.head().Start - promoters_2.head().End)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process peaks in `peak_id` data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = peaks\n",
    "peaks_promoters = promoters_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chr_start_end(peak_id):\n",
    "    parts = peak_id.split('_')\n",
    "    return parts[0], int(parts[1]), int(parts[2])\n",
    "\n",
    "def match_peaks(peaks_genes, peaks_promoters):\n",
    "    matched_peaks = []\n",
    "    \n",
    "    for _, row_peaks in peaks_genes.iterrows():\n",
    "        chr_peaks, start_peaks, end_peaks = extract_chr_start_end(row_peaks['peak_id'])\n",
    "        gene_peaks = row_peaks['gene_short_name']\n",
    "        \n",
    "        for _, row_peak_df in peaks_promoters.iterrows():\n",
    "            chr_peak_df, start_peak_df, end_peak_df = extract_chr_start_end(row_peak_df['peak_id'])\n",
    "            \n",
    "            if chr_peaks == chr_peak_df:\n",
    "                if abs(start_peaks - start_peak_df) <= 1000 or abs(end_peaks - end_peak_df) <= 1000:\n",
    "                    matched_peaks.append({\n",
    "                        'peak_id': row_peak_df['peak_id'],\n",
    "                        'gene_short_name': gene_peaks\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(matched_peaks)\n",
    "\n",
    "# matched_df = match_peaks(peaks_genes, peaks_promoters)\n",
    "# print(matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicore implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chr_start_end(peak_id):\n",
    "    parts = peak_id.split('_')\n",
    "    return parts[0], int(parts[1]), int(parts[2])\n",
    "\n",
    "def match_peaks_row(row_peaks, peak_df):\n",
    "    matched_peaks = []\n",
    "    chr_peaks, start_peaks, end_peaks = extract_chr_start_end(row_peaks['peak_id'])\n",
    "    gene_peaks = row_peaks['gene_short_name']\n",
    "    \n",
    "    for _, row_peak_df in peak_df.iterrows():\n",
    "        chr_peak_df, start_peak_df, end_peak_df = extract_chr_start_end(row_peak_df['peak_id'])\n",
    "        \n",
    "        if chr_peaks == chr_peak_df:\n",
    "            if abs(start_peaks - start_peak_df) <= 1000 or abs(end_peaks - end_peak_df) <= 1000:\n",
    "                matched_peaks.append({\n",
    "                    'peak_id': row_peak_df['peak_id'],\n",
    "                    'gene_short_name': gene_peaks\n",
    "                })\n",
    "    \n",
    "    return matched_peaks\n",
    "\n",
    "def match_peaks_parallel(peaks, peak_df, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = cpu_count()\n",
    "    \n",
    "    pool = Pool(processes=num_processes)\n",
    "    \n",
    "    results = []\n",
    "    total_rows = len(peaks)\n",
    "    \n",
    "    with tqdm(total=total_rows, desc='Matching Peaks', unit='row') as pbar:\n",
    "        for _, row_peaks in peaks.iterrows():\n",
    "            result = pool.apply_async(match_peaks_row, args=(row_peaks, peak_df), callback=lambda _: pbar.update(1))\n",
    "            results.append(result)\n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "    matched_peaks = []\n",
    "    for result in results:\n",
    "        matched_peaks.extend(result.get())\n",
    "    \n",
    "    return pd.DataFrame(matched_peaks)\n",
    "\n",
    "# matched_df = match_peaks_parallel(peaks_genes, peaks_promoters)\n",
    "# print(matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chr_start_end(peak_id):\n",
    "    parts = peak_id.split('_')\n",
    "    return parts[0], int(parts[1]), int(parts[2])\n",
    "\n",
    "def match_peaks_row(row_peaks, peak_df):\n",
    "    matched_peaks = []\n",
    "    chr_peaks, start_peaks, end_peaks = extract_chr_start_end(row_peaks['peak_id'])\n",
    "    gene_peaks = row_peaks['gene_short_name']\n",
    "    \n",
    "    # Perform the matching using cuDF\n",
    "    matched_df = peak_df[\n",
    "        (peak_df['peak_id'].str.split('_', expand=True)[0] == chr_peaks) &\n",
    "        ((peak_df['peak_id'].str.split('_', expand=True)[1].astype(int) - start_peaks).abs() <= 1000) |\n",
    "        ((peak_df['peak_id'].str.split('_', expand=True)[2].astype(int) - end_peaks).abs() <= 1000)\n",
    "    ]\n",
    "    \n",
    "    # Convert the matched cuDF DataFrame to a list of dictionaries\n",
    "    matched_peaks = matched_df.to_pandas().to_dict('records')\n",
    "    \n",
    "    return matched_peaks\n",
    "\n",
    "def match_peaks_parallel(peaks, peak_df):\n",
    "    # Convert peaks and peak_df to cuDF DataFrames\n",
    "    peaks_cudf = cudf.from_pandas(peaks)\n",
    "    peak_df_cudf = cudf.from_pandas(peak_df)\n",
    "    \n",
    "    # Convert 'peak_id' and 'gene_short_name' columns to string type\n",
    "    peaks_cudf['peak_id'] = peaks_cudf['peak_id'].astype(str)\n",
    "    peaks_cudf['gene_short_name'] = peaks_cudf['gene_short_name'].astype(str)\n",
    "    \n",
    "    # Apply the match_peaks_row function to each row of peaks_cudf using apply_rows\n",
    "    matched_peaks = []\n",
    "    for _, row in tqdm(peaks_cudf.to_pandas().iterrows(), total=len(peaks_cudf), desc='Matching Peaks'):\n",
    "        matched_peaks.extend(match_peaks_row(row, peak_df_cudf))\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    matched_df = pd.DataFrame(matched_peaks)\n",
    "    \n",
    "    # Convert the DataFrame to cuDF DataFrame\n",
    "    matched_cudf = cudf.from_pandas(matched_df)\n",
    "    \n",
    "    return matched_cudf\n",
    "\n",
    "# matched_df_1 = match_peaks_parallel(peaks_genes, peaks_promoters)\n",
    "# print(matched_df_1.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_peaks_parallel(peaks, peak_df, chunk_size=1000):\n",
    "    # Convert peaks and peak_df to cuDF DataFrames\n",
    "    peaks_cudf = cudf.from_pandas(peaks)\n",
    "    peak_df_cudf = cudf.from_pandas(peak_df)\n",
    "    \n",
    "    # Extract chr, start, and end values from peak_id using cuDF's str.split\n",
    "    peaks_cudf[['chr_peaks', 'start_peaks', 'end_peaks']] = peaks_cudf['peak_id'].str.split('_', expand=True)\n",
    "    peaks_cudf['start_peaks'] = peaks_cudf['start_peaks'].astype(int)\n",
    "    peaks_cudf['end_peaks'] = peaks_cudf['end_peaks'].astype(int)\n",
    "    \n",
    "    peak_df_cudf[['chr_peak_df', 'start_peak_df', 'end_peak_df']] = peak_df_cudf['peak_id'].str.split('_', expand=True)\n",
    "    peak_df_cudf['start_peak_df'] = peak_df_cudf['start_peak_df'].astype(int)\n",
    "    peak_df_cudf['end_peak_df'] = peak_df_cudf['end_peak_df'].astype(int)\n",
    "    \n",
    "    # Perform the matching in chunks\n",
    "    matched_dfs = []\n",
    "    for i in range(0, len(peaks_cudf), chunk_size):\n",
    "        chunk_peaks_cudf = peaks_cudf.iloc[i:i+chunk_size]\n",
    "        chunk_matched_df = chunk_peaks_cudf.merge(peak_df_cudf, left_on='chr_peaks', right_on='chr_peak_df')\n",
    "        \n",
    "        # Calculate absolute differences using apply\n",
    "        chunk_matched_df['start_diff'] = (chunk_matched_df['start_peaks'] - chunk_matched_df['start_peak_df']).abs()\n",
    "        chunk_matched_df['end_diff'] = (chunk_matched_df['end_peaks'] - chunk_matched_df['end_peak_df']).abs()\n",
    "        \n",
    "        # Filter based on the absolute differences\n",
    "        chunk_matched_df = chunk_matched_df[(chunk_matched_df['start_diff'] <= 1000) | (chunk_matched_df['end_diff'] <= 1000)]\n",
    "        chunk_matched_df = chunk_matched_df[['peak_id_y', 'gene_short_name_x']]\n",
    "        chunk_matched_df.columns = ['peak_id', 'gene_short_name']\n",
    "        matched_dfs.append(chunk_matched_df)\n",
    "    \n",
    "    # Concatenate the matched chunks\n",
    "    matched_df = cudf.concat(matched_dfs, ignore_index=True)\n",
    "    \n",
    "    return matched_df\n",
    "\n",
    "# matched_df_2 = match_peaks_parallel(peaks_genes, peaks_promoters)\n",
    "# print(matched_df_2.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process peaks in `chr, start, end` data format\n",
    "Output:\n",
    "- matched_df_1.csv\n",
    "- matched_df_1_filtered.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_genes = peaks_extended_format\n",
    "peaks_promoters = promoters_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_peaks_row(row_peaks, peaks_promoters):\n",
    "    matched_peaks = []\n",
    "    chr_peaks = row_peaks['Chr']\n",
    "    start_peaks = row_peaks['Start']\n",
    "    end_peaks = row_peaks['End']\n",
    "    gene_peaks = row_peaks['Gene']\n",
    "    \n",
    "    matched_df = peaks_promoters[\n",
    "        (peaks_promoters['Chr'] == chr_peaks) &\n",
    "        (((peaks_promoters['Start'] - start_peaks).abs() <= 5000) |\n",
    "         ((peaks_promoters['End'] - end_peaks).abs() <= 5000))\n",
    "    ]\n",
    "    \n",
    "    matched_peaks = matched_df.to_pandas().to_dict('records')\n",
    "    \n",
    "    return matched_peaks\n",
    "\n",
    "def match_peaks_parallel(peaks, peaks_promoters):\n",
    "    peaks_cudf = cudf.from_pandas(peaks)\n",
    "    peaks_promoters_cudf = cudf.from_pandas(peaks_promoters)\n",
    "    \n",
    "    peaks_cudf['Chr'] = peaks_cudf['Chr'].astype(str)\n",
    "    peaks_cudf['Gene'] = peaks_cudf['Gene'].astype(str)\n",
    "    \n",
    "    matched_peaks = []\n",
    "    for _, row in tqdm(peaks_cudf.to_pandas().iterrows(), total=len(peaks_cudf), desc='Matching peaks'):\n",
    "        matched_peaks.extend(match_peaks_row(row, peaks_promoters_cudf))\n",
    "    \n",
    "    matched_df = pd.DataFrame(matched_peaks)\n",
    "    \n",
    "    matched_cudf = cudf.from_pandas(matched_df)\n",
    "    \n",
    "    return matched_cudf\n",
    "\n",
    "matched_df_1 = match_peaks_parallel(peaks_genes, peaks_promoters)\n",
    "print(matched_df_1.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df_1.to_csv(f'{folder}peaks_matched_df_1.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df_1 = matched_df_1.sort_values('Gene')\n",
    "print(matched_df_1.shape)\n",
    "matched_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_promoters = peaks_promoters.sort_values('Gene')\n",
    "print(peaks_promoters.shape)\n",
    "peaks_promoters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_promoters[peaks_promoters.Start == 219132893]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df_1_filtered = matched_df_1.drop_duplicates(subset=['Start', 'End', 'Gene'])\n",
    "print(matched_df_1_filtered.shape)\n",
    "matched_df_1_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df_1_filtered.to_csv(f'{folder}peaks_matched_df_1_filtered.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(peaks_genes['Gene']) & set(peaks_promoters['Gene'])\n",
    "\n",
    "count = len(intersection)\n",
    "\n",
    "# print(\"Intersection:\", intersection)\n",
    "print(len(peaks_genes['Gene'].unique()))\n",
    "print(len(peaks_promoters['Gene'].unique()))\n",
    "print(\"Intersection Count:\", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rapids)",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
